{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network - MLP Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import category_encoders as ce\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from skopt import BayesSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ali_m\\AppData\\Local\\Temp\\ipykernel_27268\\2795191405.py:1: DtypeWarning: Columns (45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_day_minus_0 = pd.read_csv('C:/com748/code/com748/data/processed/balanced_dataset/day_minus_0.csv')\n"
     ]
    }
   ],
   "source": [
    "df_day_minus_0 = pd.read_csv('C:/com748/code/com748/data/processed/balanced_dataset/day_minus_0.csv')\n",
    "df_day_minus_1 = pd.read_csv('C:/com748/code/com748/data/processed/balanced_dataset/day_minus_1.csv')\n",
    "df_day_minus_2 = pd.read_csv('C:/com748/code/com748/data/processed/balanced_dataset/day_minus_2.csv')\n",
    "df_day_minus_7 = pd.read_csv('C:/com748/code/com748/data/processed/balanced_dataset/day_minus_7.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day_minus_0 = df_day_minus_0.drop(columns=['date','file_date'], axis=1)\n",
    "df_day_minus_1 = df_day_minus_1.drop(columns=['date'], axis=1)\n",
    "df_day_minus_2 = df_day_minus_2.drop(columns=['date'], axis=1)\n",
    "df_day_minus_7 = df_day_minus_7.drop(columns=['date'], axis=1)\n",
    "\n",
    "df_day_minus_0['null_columns'] = df_day_minus_0.isnull().sum(axis=1)\n",
    "df_day_minus_1['null_columns'] = df_day_minus_1.isnull().sum(axis=1)\n",
    "df_day_minus_2['null_columns'] = df_day_minus_2.isnull().sum(axis=1)\n",
    "df_day_minus_7['null_columns'] = df_day_minus_7.isnull().sum(axis=1)\n",
    "\n",
    "df_day_minus_0 = df_day_minus_0[df_day_minus_0.null_columns == 0]\n",
    "df_day_minus_1 = df_day_minus_1[df_day_minus_1.null_columns == 0]\n",
    "df_day_minus_2 = df_day_minus_2[df_day_minus_2.null_columns == 0]\n",
    "df_day_minus_7 = df_day_minus_7[df_day_minus_7.null_columns == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split into x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0 = df_day_minus_0.drop(columns=['failure', 'serial_number', 'null_columns'], axis=1)\n",
    "X_1 = df_day_minus_1.drop(columns=['failure', 'serial_number', 'null_columns'], axis=1)\n",
    "X_2 = df_day_minus_2.drop(columns=['failure', 'serial_number', 'null_columns'], axis=1)\n",
    "X_7 = df_day_minus_7.drop(columns=['failure', 'serial_number', 'null_columns'], axis=1)\n",
    "\n",
    "Y_0 = df_day_minus_0['failure']\n",
    "Y_1 = df_day_minus_1['failure']\n",
    "Y_2 = df_day_minus_2['failure']\n",
    "Y_7 = df_day_minus_7['failure']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_0 = ce.OrdinalEncoder(cols=['model', 'capacity_bytes'])\n",
    "encoder_1 = ce.OrdinalEncoder(cols=['model', 'capacity_bytes'])\n",
    "encoder_2 = ce.OrdinalEncoder(cols=['model', 'capacity_bytes'])\n",
    "encoder_7 = ce.OrdinalEncoder(cols=['model', 'capacity_bytes'])\n",
    "\n",
    "X_train_0, X_test_0, y_train_0, y_test_0 = train_test_split(X_0, Y_0, test_size=0.2, random_state=42)\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_1, Y_1, test_size=0.2, random_state=42)\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, Y_2, test_size=0.2, random_state=42)\n",
    "X_train_7, X_test_7, y_train_7, y_test_7 = train_test_split(X_7, Y_7, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_0 = encoder_0.fit_transform(X_train_0)\n",
    "X_test_0 = encoder_0.transform(X_test_0)\n",
    "\n",
    "X_train_1 = encoder_1.fit_transform(X_train_1)\n",
    "X_test_1 = encoder_1.transform(X_test_1)\n",
    "\n",
    "X_train_2 = encoder_2.fit_transform(X_train_2)\n",
    "X_test_2 = encoder_2.transform(X_test_2)\n",
    "\n",
    "X_train_7 = encoder_0.fit_transform(X_train_7)\n",
    "X_test_7 = encoder_0.transform(X_test_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Scaling (Using robust scaler to handle outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              model  capacity_bytes  smart_1_normalized   smart_1_raw  \\\n",
      "count  21612.000000    21612.000000        21612.000000  2.161200e+04   \n",
      "mean       2.760087        2.085045           96.274986  1.223515e+08   \n",
      "std        1.841142        1.131281           19.810505  7.039539e+07   \n",
      "min        1.000000        1.000000           37.000000  0.000000e+00   \n",
      "25%        1.000000        1.000000           80.000000  6.115209e+07   \n",
      "50%        2.000000        2.000000          100.000000  1.227242e+08   \n",
      "75%        4.000000        3.000000          116.000000  1.831709e+08   \n",
      "max        7.000000        5.000000          120.000000  2.441335e+08   \n",
      "\n",
      "       smart_3_normalized  smart_3_raw  smart_4_normalized   smart_4_raw  \\\n",
      "count        21612.000000      21612.0        21612.000000  21612.000000   \n",
      "mean            92.509856          0.0           99.998843     15.467472   \n",
      "std              3.375152          0.0            0.055668     72.197321   \n",
      "min             83.000000          0.0           95.000000      1.000000   \n",
      "25%             91.000000          0.0          100.000000      5.000000   \n",
      "50%             92.000000          0.0          100.000000      9.000000   \n",
      "75%             95.000000          0.0          100.000000     16.000000   \n",
      "max            100.000000          0.0          100.000000   5403.000000   \n",
      "\n",
      "       smart_5_normalized   smart_5_raw  ...  smart_198_normalized  \\\n",
      "count        21612.000000  21612.000000  ...          21612.000000   \n",
      "mean            98.744633   2123.267444  ...             99.423607   \n",
      "std              6.796124   8195.176329  ...              5.896917   \n",
      "min              1.000000      0.000000  ...              1.000000   \n",
      "25%            100.000000      0.000000  ...            100.000000   \n",
      "50%            100.000000      0.000000  ...            100.000000   \n",
      "75%            100.000000      8.000000  ...            100.000000   \n",
      "max            100.000000  65528.000000  ...            100.000000   \n",
      "\n",
      "       smart_198_raw  smart_199_normalized  smart_199_raw  \\\n",
      "count   21612.000000               21612.0   21612.000000   \n",
      "mean      269.473256                 200.0      16.744725   \n",
      "std      4737.194484                   0.0     469.067102   \n",
      "min         0.000000                 200.0       0.000000   \n",
      "25%         0.000000                 200.0       0.000000   \n",
      "50%         0.000000                 200.0       0.000000   \n",
      "75%         0.000000                 200.0       0.000000   \n",
      "max    462016.000000                 200.0   48096.000000   \n",
      "\n",
      "       smart_240_normalized  smart_240_raw  smart_241_normalized  \\\n",
      "count               21612.0   2.161200e+04               21612.0   \n",
      "mean                  100.0   2.034123e+13                 100.0   \n",
      "std                     0.0   5.844404e+13                   0.0   \n",
      "min                   100.0   0.000000e+00                 100.0   \n",
      "25%                   100.0   1.453300e+04                 100.0   \n",
      "50%                   100.0   2.890900e+04                 100.0   \n",
      "75%                   100.0   5.434025e+04                 100.0   \n",
      "max                   100.0   2.814406e+14                 100.0   \n",
      "\n",
      "       smart_241_raw  smart_242_normalized  smart_242_raw  \n",
      "count   2.161200e+04               21612.0   2.161200e+04  \n",
      "mean    3.810722e+11                 100.0   1.318175e+13  \n",
      "std     4.977389e+12                   0.0   4.751957e+13  \n",
      "min     0.000000e+00                 100.0   3.912000e+03  \n",
      "25%     3.262883e+10                 100.0   9.830136e+10  \n",
      "50%     5.949665e+10                 100.0   2.149119e+11  \n",
      "75%     8.241097e+10                 100.0   4.040086e+11  \n",
      "max     1.959887e+14                 100.0   2.811722e+14  \n",
      "\n",
      "[8 rows x 42 columns]\n",
      "              model  capacity_bytes  smart_1_normalized   smart_1_raw  \\\n",
      "count  21612.000000    21612.000000        21612.000000  21612.000000   \n",
      "mean       0.253362        0.042523           -0.103473     -0.003055   \n",
      "std        0.613714        0.565641            0.550292      0.576923   \n",
      "min       -0.333333       -0.500000           -1.750000     -1.005781   \n",
      "25%       -0.333333       -0.500000           -0.555556     -0.504612   \n",
      "50%        0.000000        0.000000            0.000000      0.000000   \n",
      "75%        0.666667        0.500000            0.444444      0.495388   \n",
      "max        1.666667        1.500000            0.555556      0.995005   \n",
      "\n",
      "       smart_3_normalized  smart_3_raw  smart_4_normalized   smart_4_raw  \\\n",
      "count        21612.000000      21612.0        21612.000000  21612.000000   \n",
      "mean             0.127464          0.0           -0.001157      0.587952   \n",
      "std              0.843788          0.0            0.055668      6.563393   \n",
      "min             -2.250000          0.0           -5.000000     -0.727273   \n",
      "25%             -0.250000          0.0            0.000000     -0.363636   \n",
      "50%              0.000000          0.0            0.000000      0.000000   \n",
      "75%              0.750000          0.0            0.000000      0.636364   \n",
      "max              2.000000          0.0            0.000000    490.363636   \n",
      "\n",
      "       smart_5_normalized   smart_5_raw  ...  smart_198_normalized  \\\n",
      "count        21612.000000  21612.000000  ...          21612.000000   \n",
      "mean            -1.255367    265.408431  ...             -0.576393   \n",
      "std              6.796124   1024.397041  ...              5.896917   \n",
      "min            -99.000000      0.000000  ...            -99.000000   \n",
      "25%              0.000000      0.000000  ...              0.000000   \n",
      "50%              0.000000      0.000000  ...              0.000000   \n",
      "75%              0.000000      1.000000  ...              0.000000   \n",
      "max              0.000000   8191.000000  ...              0.000000   \n",
      "\n",
      "       smart_198_raw  smart_199_normalized  smart_199_raw  \\\n",
      "count   21612.000000               21612.0   21612.000000   \n",
      "mean      269.473256                   0.0      16.744725   \n",
      "std      4737.194484                   0.0     469.067102   \n",
      "min         0.000000                   0.0       0.000000   \n",
      "25%         0.000000                   0.0       0.000000   \n",
      "50%         0.000000                   0.0       0.000000   \n",
      "75%         0.000000                   0.0       0.000000   \n",
      "max    462016.000000                   0.0   48096.000000   \n",
      "\n",
      "       smart_240_normalized  smart_240_raw  smart_241_normalized  \\\n",
      "count               21612.0   2.161200e+04               21612.0   \n",
      "mean                    0.0   5.109932e+08                   0.0   \n",
      "std                     0.0   1.468176e+09                   0.0   \n",
      "min                     0.0  -7.262245e-01                   0.0   \n",
      "25%                     0.0  -3.611402e-01                   0.0   \n",
      "50%                     0.0   0.000000e+00                   0.0   \n",
      "75%                     0.0   6.388598e-01                   0.0   \n",
      "max                     0.0   7.070084e+09                   0.0   \n",
      "\n",
      "       smart_241_raw  smart_242_normalized  smart_242_raw  \n",
      "count   21612.000000               21612.0   21612.000000  \n",
      "mean        6.459658                   0.0      42.415873  \n",
      "std        99.983426                   0.0     155.441417  \n",
      "min        -1.195141                   0.0      -0.702999  \n",
      "25%        -0.539708                   0.0      -0.381445  \n",
      "50%         0.000000                   0.0       0.000000  \n",
      "75%         0.460292                   0.0       0.618555  \n",
      "max      3935.732244                   0.0     919.040437  \n",
      "\n",
      "[8 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "print(X_train_0.describe())\n",
    "scaled_X_train_0 = X_train_0.copy()\n",
    "\n",
    "r_scaler = RobustScaler()\n",
    "scaled_X_train_0[scaled_X_train_0.columns] = r_scaler.fit_transform(scaled_X_train_0[scaled_X_train_0.columns])\n",
    "\n",
    "print(scaled_X_train_0.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\com748\\code\\com748\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'adam', 'max_iter': 1000, 'learning_rate': 'constant', 'hidden_layer_sizes': (100,), 'alpha': 0.0001, 'activation': 'tanh'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize the MLP model\n",
    "mlp_model_0_cv = MLPClassifier(random_state=90)\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 100)],\n",
    "    'activation': ['logistic', 'tanh'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "    'max_iter': [100, 500, 1000]\n",
    "}\n",
    "\n",
    "rand_search_0 = RandomizedSearchCV(mlp_model_0_cv, param_grid, cv=5, scoring='roc_auc', n_iter=40)\n",
    "rand_search_0.fit(scaled_X_train_0, y_train_0)\n",
    "\n",
    "print(rand_search_0.best_params_)\n",
    "\n",
    "df_randsearch_results_0 = pd.DataFrame(rand_search_0.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Day minus 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2307  373]\n",
      " [ 651 2072]]\n",
      "Test Accuracy: 0.8104756616694428\n"
     ]
    }
   ],
   "source": [
    "# Best params: {'solver': 'adam', 'max_iter': 1000, 'learning_rate': 'constant', 'hidden_layer_sizes': (100,), 'alpha': 0.0001, 'activation': 'tanh'}\n",
    "\n",
    "# scale test dataset using scaler fitted on training\n",
    "scaled_X_test_0 = X_test_0.copy()\n",
    "scaled_X_test_0[scaled_X_test_0.columns] = r_scaler.transform(scaled_X_test_0[scaled_X_test_0.columns])\n",
    "\n",
    "mlp_model_0 = MLPClassifier(solver='adam', max_iter=1000, alpha=0.0001, learning_rate='constant', hidden_layer_sizes=(100,), activation='tanh', random_state=90)\n",
    "mlp_model_0.fit(scaled_X_train_0, y_train_0)\n",
    "\n",
    "test_predictions_0 = mlp_model_0.predict(scaled_X_test_0)\n",
    "cm = confusion_matrix(y_true=y_test_0, y_pred=test_predictions_0)\n",
    "print(cm)\n",
    "\n",
    "# Evaluate the model on test set\n",
    "test_accuracy_0 = mlp_model_0.score(scaled_X_test_0, y_test_0)\n",
    "print(\"Test Accuracy:\", test_accuracy_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smart_187_raw\t\t0.114 +/- 0.005\n",
      "smart_198_raw\t\t0.100 +/- 0.004\n",
      "smart_5_raw\t\t0.096 +/- 0.005\n",
      "smart_187_normalized\t\t0.059 +/- 0.003\n",
      "smart_197_raw\t\t0.054 +/- 0.003\n",
      "smart_5_normalized\t\t0.048 +/- 0.003\n",
      "smart_188_raw\t\t0.029 +/- 0.002\n",
      "smart_242_raw\t\t0.023 +/- 0.002\n",
      "smart_240_raw\t\t0.023 +/- 0.002\n",
      "capacity_bytes\t\t0.018 +/- 0.002\n",
      "smart_241_raw\t\t0.017 +/- 0.002\n",
      "smart_4_raw\t\t0.011 +/- 0.001\n",
      "smart_192_raw\t\t0.010 +/- 0.001\n",
      "smart_198_normalized\t\t0.008 +/- 0.001\n",
      "smart_197_normalized\t\t0.008 +/- 0.001\n",
      "smart_7_raw\t\t0.008 +/- 0.001\n",
      "smart_199_raw\t\t0.006 +/- 0.001\n",
      "smart_7_normalized\t\t0.005 +/- 0.001\n",
      "smart_193_normalized\t\t0.004 +/- 0.001\n",
      "smart_193_raw\t\t0.004 +/- 0.001\n",
      "smart_9_normalized\t\t0.003 +/- 0.001\n",
      "smart_9_raw\t\t0.003 +/- 0.001\n",
      "smart_12_raw\t\t0.003 +/- 0.001\n",
      "smart_1_normalized\t\t0.003 +/- 0.001\n",
      "smart_3_normalized\t\t0.003 +/- 0.001\n",
      "model   \t\t0.003 +/- 0.001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "r = permutation_importance(mlp_model_0, scaled_X_test_0, y_test_0,\n",
    "                           n_repeats=30,\n",
    "                           random_state=0,\n",
    "                           scoring='roc_auc')\n",
    "\n",
    "for i in r.importances_mean.argsort()[::-1]:\n",
    "    if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "        print(f\"{scaled_X_test_0.columns[i]:<8}\\t\\t\"\n",
    "              f\"{r.importances_mean[i]:.3f}\"\n",
    "              f\" +/- {r.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = r.importances_mean\n",
    "std = r.importances_std\n",
    "permutation_importances_0 = pd.DataFrame({'mean_importance': mean, 'std_importance': std}, index=scaled_X_test_0.columns)\n",
    "permutation_importances_0['feature'] = permutation_importances_0.index\n",
    "permutation_importances_0.sort_values(by=['mean_importance'], ascending=False, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
