{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset of non-failing HDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import dask.dataframe as ddf\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get list of serial numbers for all drives that have failed. Use list to ignore these HDDs when collecting non-failing drives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\n",
      "ST4000DM000      5602\n",
      "ST12000NM0007    2106\n",
      "ST8000NM0055     1718\n",
      "ST3000DM001      1454\n",
      "ST12000NM0008    1349\n",
      "ST8000DM002      1037\n",
      "ST14000NM001G     418\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Read day_minus_0 failures data (all failures in the dataset)\n",
    "df_day_minus_0 = pd.read_csv('C:/com748/code/com748/data/processed/day_minus_0/failures.csv')\n",
    "failed_drives = df_day_minus_0.serial_number.unique()\n",
    "failure_days = df_day_minus_0.file_date.value_counts()\n",
    "model_failure_counts = df_day_minus_0.model.value_counts()\n",
    "\n",
    "# Use model failure counts to find and balance with healthy drives\n",
    "print(model_failure_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model ST4000DM000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_target_value = 5602\n",
    "\n",
    "parquet_files = glob.glob('C:/com748/data/processed/daily/*.parquet')\n",
    "\n",
    "rows_list = []\n",
    "\n",
    "for file in reversed(parquet_files):\n",
    "\n",
    "    date = Path(file).stem\n",
    "    df = pd.read_parquet(file, engine='pyarrow', filters=[(\"model\", \"==\", \"ST4000DM000\")])\n",
    "\n",
    "    if len(df.index) == 0: continue\n",
    "\n",
    "    df_filtered = df[~df['serial_number'].isin(failed_drives)]\n",
    "\n",
    "    if len(df_filtered.index) == 0: continue\n",
    "\n",
    "    daily_sample_count = 20\n",
    "    row_count = len(df_filtered.index)\n",
    "    sample_size = min(daily_sample_count, row_count)\n",
    "\n",
    "    df_random_sample = df_filtered.sample(n=sample_size, ignore_index=True)\n",
    "    df_random_sample_dict = df_random_sample.to_dict(orient='records')\n",
    "\n",
    "    rows_list.extend(df_random_sample_dict)\n",
    "\n",
    "df_non_failing_drives = pd.DataFrame(rows_list)\n",
    "df_non_failing_drives.to_csv('C:/com748/code/com748/data/processed/non_failing_drives/random_ST4000DM000.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
